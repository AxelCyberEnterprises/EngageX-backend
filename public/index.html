<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebSocket Video & Audio Streaming</title>
</head>

<body>
    <h2>WebSocket Video Streaming</h2>
    <video id="videoPreview" autoplay></video>
    <button id="startBtn">Start Recording</button>
    <button id="stopBtn" disabled>Stop Recording</button>
    <p id="status">Status: Waiting...</p>

    <script>
        let videoRecorder, audioRecorder;
        let socket;
        let chunkCounter = 0;
        let videoBlob = null, audioBlob = null;

        document.getElementById("startBtn").addEventListener("click", async function () {
            try {
                // Request camera & microphone access
                const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                document.getElementById("videoPreview").srcObject = stream;

                // Extract audio-only stream
                const audioStream = new MediaStream(stream.getAudioTracks());

                // Initialize WebSocket
                socket = new WebSocket("ws://localhost:8000/ws/socket_server/");
                socket.onopen = () => console.log("WebSocket Connected");
                socket.onmessage = (e) => console.log("Server:", JSON.parse(e.data));
                socket.onerror = (error) => console.error("WebSocket Error:", error);
                socket.onclose = () => console.log("WebSocket Disconnected");

                // Initialize Video Recorder
                videoRecorder = new MediaRecorder(stream, { mimeType: "video/webm" });
                videoRecorder.ondataavailable = (event) => {
                    if (event.data && event.data.size > 0) {
                        videoBlob = event.data; // Directly assign the blob
                        sendCombinedChunk();
                    }
                };

                // Initialize Audio-Only Recorder
                audioRecorder = new MediaRecorder(audioStream, { mimeType: "audio/webm" });
                audioRecorder.ondataavailable = (event) => {
                    if (event.data && event.data.size > 0) {
                        audioBlob = event.data; // Directly assign the blob
                        sendCombinedChunk();
                    }
                };

               // Start recording
			   videoRecorder.start();
                audioRecorder.start();

                // Request data every 15 seconds
                setInterval(() => {
                    videoRecorder.requestData();
                    audioRecorder.requestData();
                }, 15000); // Adjust timing if needed

                // UI updates
                document.getElementById("startBtn").disabled = true;
                document.getElementById("stopBtn").disabled = false;
            } catch (error) {
                console.error("Camera Access Error:", error);
            }
        });
		
        function sendCombinedChunk() {
            // Defensive check for blobs and WebSocket state
            if (videoBlob && audioBlob && socket && socket.readyState === WebSocket.OPEN) {
                chunkCounter++;

                const readerV = new FileReader();
                const readerA = new FileReader();

                readerV.onloadend = () => {
                    readerA.onloadend = () => {
                        const payload = {
                            type: "video_audio",
                            chunk: chunkCounter,
                            video: readerV.result.split(",")[1], // Base64 encoding
                            audio: readerA.result.split(",")[1], // Base64 encoding
                        };
                        
                        try {
                            socket.send(JSON.stringify(payload));
                            console.log(`Sent Combined Chunk ${chunkCounter}`);
                        } catch (error) {
                            console.error("WebSocket Send Error:", error);
                        }
                    };
                    
                    // Ensure audioBlob is used
                    if (audioBlob) {
                        readerA.readAsDataURL(audioBlob);
                    }
                };

                // Only proceed if videoBlob exists
                if (videoBlob) {
                    readerV.readAsDataURL(videoBlob);
                }

                // Reset blobs for the next chunk
                videoBlob = null;
                audioBlob = null;
            }
        }

        document.getElementById("stopBtn").addEventListener("click", function () {
            if (videoRecorder) videoRecorder.stop();
            if (audioRecorder) audioRecorder.stop();
            
            if (socket) {
                socket.close();
            }

            document.getElementById("status").textContent = "Status: Stopped";
            document.getElementById("startBtn").disabled = false;
            document.getElementById("stopBtn").disabled = true;
        });
    </script>
</body>